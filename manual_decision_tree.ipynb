{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_12500\\1662815981.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width    type\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa\n",
       "5           5.4          3.9           1.7          0.4  setosa\n",
       "6           4.6          3.4           1.4          0.3  setosa\n",
       "7           5.0          3.4           1.5          0.2  setosa\n",
       "8           4.4          2.9           1.4          0.2  setosa\n",
       "9           4.9          3.1           1.5          0.1  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'type']\n",
    "data = pd.read_csv(\"iris.csv\", skiprows=1, header=None, names=  col_names)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold= None, left=None, right=None, info_gain=None, value=None):\n",
    "        # for internal nodes \n",
    "        self.feature_index= feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        \n",
    "        # for lead nodes\n",
    "        self.value = value\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth = 2, min_samples_split = 2):\n",
    "        # initialize the root\n",
    "        self.root = None\n",
    "\n",
    "        #stopping condition\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "\n",
    "    def build_tree(self,dataset,cur_depth=0):\n",
    "        ''' to build a prtiular node '''\n",
    "        X,Y = dataset[:,:-1] , dataset[:,-1]\n",
    "        num_samples , num_features = np.shape(X)\n",
    "\n",
    "\n",
    "        #split until stopping conditions are met\n",
    "        if cur_depth <= self.max_depth and num_samples >= self.min_samples_split:\n",
    "            #find the best split\n",
    "            best_split = self.get_best_split(dataset,num_samples, num_features)\n",
    "            #check if information gain is positive\n",
    "            if best_split['info_gain'] > 0:\n",
    "                # recur left\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], cur_depth+1)\n",
    "                # recur right\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], cur_depth+1)\n",
    "                # return decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "            \n",
    "            # compute leaf node \n",
    "            leaf_value = self.calculate_leaf_values(Y)\n",
    "            #return leaf node\n",
    "            return Node(value = leaf_value)\n",
    "        \n",
    "        def get_best_split(self, dataset, num_samples, num_features):\n",
    "            ''' function to find the best split'''\n",
    "\n",
    "            # dictionary to store the best split\n",
    "            best_split = {}\n",
    "            max_info_gain = -float(\"inf\")\n",
    "\n",
    "            #loop over all the features\n",
    "            for feature_index in range(num_features):\n",
    "                feature_values = dataset[:, feature_index]\n",
    "                possible_thresholds = np.unique(feature_values)\n",
    "\n",
    "                for threshold in possible_thresholds:\n",
    "                    # get current split\n",
    "                    dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                    # check if chlidren are not null\n",
    "                    if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                        y , left_y, right_y = dataset[:, -1] , dataset_left[:, -1], dataset_right[:, -1]\n",
    "                        # compute information gain\n",
    "                        cur_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                        #update the best split if needed\n",
    "                        if cur_info_gain > max_info_gain:\n",
    "                            best_split[\"feature_index\"] = feature_index\n",
    "                            best_split['threshold'] = threshold\n",
    "                            best_split[\"dataset_left\"] = dataset_left\n",
    "                            best_split[\"dataset_right\"] = dataset_right\n",
    "                            max_info_gain = cur_info_gain\n",
    "                            best_split[\"info_gain\"] = max_info_gain\n",
    "\n",
    "            \n",
    "            return best_split\n",
    "        \n",
    "        def split(self, dataset, feature_index, threshold):\n",
    "            ''' function to split the data '''\n",
    "            dataset_left  = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
    "            dataset_right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
    "            return dataset_left, dataset_right\n",
    "        \n",
    "        def information_gain(self, parent, l_child, r_child, mode = \"entropy\"):\n",
    "            ''' function to compute information gain'''\n",
    "\n",
    "            weight_l = len(l_child) / len(parent)\n",
    "            weight_r = len(r_child) / len(parent)\n",
    "\n",
    "            if mode == \"gini\":\n",
    "                gain = self.gini_index(parent) - weight_l*self.gini_index(l_child) - - weight_r*self.gini_index(r_child)\n",
    "            else:\n",
    "                gain = self.entropy(parent) - (weight_l * self.entropy(l_child)) - (weight_r*self.entropy(r_child))\n",
    "\n",
    "            return gain\n",
    "\n",
    "        def entropy(self,y):\n",
    "            ''' function to compute entropy '''\n",
    "\n",
    "            class_labels = np.unique(y)\n",
    "            entropy = 0\n",
    "            for cls in class_labels:\n",
    "                p_cls = len(y[y == cls]) / len(y)\n",
    "                entropy += -p_cls * np.log2(p_cls)\n",
    "            \n",
    "            return entropy\n",
    "        \n",
    "        def gini_index(self, y):\n",
    "            ''' function to compute gini index'''\n",
    "            class_labels = np.unique(y)\n",
    "            gini = 0\n",
    "            for cls in class_labels:\n",
    "                p_cls = llen(y[y == cls]) / len(y)\n",
    "                gini += p_cls**2\n",
    "            return 1 - gini\n",
    "        \n",
    "        def calculate_leaf_value(self, y):\n",
    "            y = list(y)\n",
    "            return max(y, key = y.count)\n",
    "        \n",
    "        def print_tree(self, tree=None, indent = \" \"):\n",
    "            pass\n",
    "        \n",
    "        def fit(self, X, Y):\n",
    "            ''' function to train the tree '''\n",
    "\n",
    "            dataset = np.concatenate((X,Y), axis = 1)\n",
    "            self.root = self.build_tree(dataset)\n",
    "\n",
    "        def predict(self , X):\n",
    "            ''' function to predict new dataset '''\n",
    "\n",
    "            predictions = [self.make_prediction(x,self.root) for x in x]\n",
    "            return predictions\n",
    "        \n",
    "        def make_prediction(self, x, tree):\n",
    "            ''' function to predict a single data point'''\n",
    "            \n",
    "            if tree.value != None: return tree.value\n",
    "            feature_val = x[tree.feature_index]\n",
    "            if feature_val <= tree.threshold:\n",
    "                return self.make_prediction(x, tree.left)\n",
    "            else:\n",
    "                return self.make_prediction(x, tree.right)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = .2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
